{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MATH 4060 - Markov Decision Processes and Reinforcement Learning - Final Project**\n",
        "\n",
        "# Can't Stop AI"
      ],
      "metadata": {
        "id": "ykVnQgsPS5HH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR9Z_cjkWdDf"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import jax.numpy as jnp\n",
        "from jax import random as jrandom\n",
        "from jax import nn as jnn\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import jax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Given"
      ],
      "metadata": {
        "id": "aVlr6jvJV_ZH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP4PMjNiK9oz"
      },
      "source": [
        "## Variable descriptions and Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1c91_Y1IaQW",
        "outputId": "eb78db9a-e0af-43cf-d325-92077b20d569"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Implementation of the board game \"CANT STOP\"\\n\\nHow the game is represented in Python:\\n\\n-----Game parameters (that do not change while the game is being played)\\n\\nN_PLAYERS\\n   A postive integer\\n  This is the number of players playing\\n  In the classic game rules, N_Players = 4\\n\\nN_COL_TO_WIN\\n   A positive integer\\n   This is the number of columns you need to claim to win the game\\n   In the classic game rules, N_Col_To_Win = 3\\n\\nN_MAX_RUNNERS\\n   A positive integer\\n   This is the maximum number of runners you can have\\n   In the classic game rules, N_Max_Runners = 3\\n\\nPLAYER_COL_STATE_INIT\\n   An vector of shape (11,) of non-negative integers\\n   This is the number of squares in each game column\\n   In the classic game rules, this is [3,5,7,9,11,13,11,9,7,5,3]\\n\\nNOTE on column labelling:\\n   In the game, the columns are labeled 2-12 (corresponding to dice rolls)\\n   In Python, the columns locations are indexed 0-10\\n   This means that to translate from column in Python to columns in the game,\\n   one must often add or subtract 2 from the column indices. \\n\\n---Variables: (that represent what is going on in the game as it is played)\\n\\nactive_player_index\\n   An index from the range [0,N_PLAYERS-1] indicating whose turn it current is\\n\\nplayer_col_state\\n   An array of shape (N_players,11) of integers\\n   Each row is the number of squares remaining for that player in each col\\n   NOTE: \\n     This is the number of squares REMAINING, these start at PLAYER_COL_STATE_INIT\\n     and count DOWN to zero as the game progresses. When the get to zero, the player has claimed the column\\n   WARNING:\\n     We will not prohibit these from being negative even though it doesn\\'t mean anything in the game\\n     (This can happen if the player goes past the number needed to claim the column)\\n\\nillegal_col\\n   A vector of shape (11,) of boolean\\n   Contains the information on which columns are still in play\\n   (columns that have been claimed by a player are not legal to play in anymore)\\n\\nrunner_col_state\\n  A vector of shape (11,) of non-negative integers\\n  Indicates the current state of how far the runners have advanced in each column\\n  A zero indicates that there is no runner in that column at all\\n  NOTES:\\n   1. count_nonzero(runner_col) should not exceed N_Max_Runners for legal runner states\\n   2. Since player_col_state counts DOWN to 0, runner_col is SUBTRACTED from player_col_state when the player chooses to stop rolling\\n\\ndice_rolls\\n  A vector of shape (4,) of integers [1,6] indicating the outcome of the 4 dice rolls\\n\\nrunner_col_choices\\n  A vector of shape (N_choices, 11) of non-negative integers\\n  Indicates the available CHOICES the player has of where the runners could be\\n  This corresponds to legal choices for choosing pairings of the dice\\n  NOTES:\\n    1. By the rules of the game, N_choices can be at most 6\\n    2. If N_choices = 0, then this indicates that there are no legal moves and the player has busted\\n\\nroll_again\\n  A boolean on whether or not the player wants to rolls again'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''Implementation of the board game \"CANT STOP\"\n",
        "\n",
        "How the game is represented in Python:\n",
        "\n",
        "-----Game parameters (that do not change while the game is being played)\n",
        "\n",
        "N_PLAYERS\n",
        "   A postive integer\n",
        "  This is the number of players playing\n",
        "  In the classic game rules, N_Players = 4\n",
        "\n",
        "N_COL_TO_WIN\n",
        "   A positive integer\n",
        "   This is the number of columns you need to claim to win the game\n",
        "   In the classic game rules, N_Col_To_Win = 3\n",
        "\n",
        "N_MAX_RUNNERS\n",
        "   A positive integer\n",
        "   This is the maximum number of runners you can have\n",
        "   In the classic game rules, N_Max_Runners = 3\n",
        "\n",
        "PLAYER_COL_STATE_INIT\n",
        "   An vector of shape (11,) of non-negative integers\n",
        "   This is the number of squares in each game column\n",
        "   In the classic game rules, this is [3,5,7,9,11,13,11,9,7,5,3]\n",
        "\n",
        "NOTE on column labelling:\n",
        "   In the game, the columns are labeled 2-12 (corresponding to dice rolls)\n",
        "   In Python, the columns locations are indexed 0-10\n",
        "   This means that to translate from column in Python to columns in the game,\n",
        "   one must often add or subtract 2 from the column indices. \n",
        "\n",
        "---Variables: (that represent what is going on in the game as it is played)\n",
        "\n",
        "active_player_index\n",
        "   An index from the range [0,N_PLAYERS-1] indicating whose turn it current is\n",
        "\n",
        "player_col_state\n",
        "   An array of shape (N_players,11) of integers\n",
        "   Each row is the number of squares remaining for that player in each col\n",
        "   NOTE: \n",
        "     This is the number of squares REMAINING, these start at PLAYER_COL_STATE_INIT\n",
        "     and count DOWN to zero as the game progresses. When the get to zero, the player has claimed the column\n",
        "   WARNING:\n",
        "     We will not prohibit these from being negative even though it doesn't mean anything in the game\n",
        "     (This can happen if the player goes past the number needed to claim the column)\n",
        "\n",
        "illegal_col\n",
        "   A vector of shape (11,) of boolean\n",
        "   Contains the information on which columns are still in play\n",
        "   (columns that have been claimed by a player are not legal to play in anymore)\n",
        "\n",
        "runner_col_state\n",
        "  A vector of shape (11,) of non-negative integers\n",
        "  Indicates the current state of how far the runners have advanced in each column\n",
        "  A zero indicates that there is no runner in that column at all\n",
        "  NOTES:\n",
        "   1. count_nonzero(runner_col) should not exceed N_Max_Runners for legal runner states\n",
        "   2. Since player_col_state counts DOWN to 0, runner_col is SUBTRACTED from player_col_state when the player chooses to stop rolling\n",
        "\n",
        "dice_rolls\n",
        "  A vector of shape (4,) of integers [1,6] indicating the outcome of the 4 dice rolls\n",
        "\n",
        "runner_col_choices\n",
        "  A vector of shape (N_choices, 11) of non-negative integers\n",
        "  Indicates the available CHOICES the player has of where the runners could be\n",
        "  This corresponds to legal choices for choosing pairings of the dice\n",
        "  NOTES:\n",
        "    1. By the rules of the game, N_choices can be at most 6\n",
        "    2. If N_choices = 0, then this indicates that there are no legal moves and the player has busted\n",
        "\n",
        "roll_again\n",
        "  A boolean on whether or not the player wants to rolls again'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCJT-pJc532s"
      },
      "source": [
        "## Dice Functions\n",
        "Note that we will compress the four 6-sided dice rolls down to an integer in the range $[0,1295]$ which we call the `diceNum`. This is done by thinking of the roll as a 4 digit number in base 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4GVGRAK6CU6"
      },
      "outputs": [],
      "source": [
        "def diceRoll_to_diceNum(diceRollArray):\n",
        "  '''Converts an array of shape (4,) of the four 6 sided dice to the diceNum in [0,1295]'''\n",
        "  #Note: Dice rolls are assumed to be numbers 1-6 (i.e. they start at 1!)\n",
        "  powersOfSix = jnp.array([1,6,36,216])\n",
        "  return jnp.inner(powersOfSix, jnp.array(diceRollArray)-1)\n",
        "\n",
        "def diceNum_to_diceRoll(diceNum):\n",
        "  '''Converts the diceNum in [0,1295] to an array of an array of shape (4,) of the 4 dice rolls'''\n",
        "  #Note: Dice rolls are assumed to be numbers 1-6 (i.e. they start at 1!)\n",
        "  powersOfSix = jnp.array([1,6,36,216])\n",
        "\n",
        "  return 1+(diceNum // powersOfSix) % 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9VgWRXw9ZuM"
      },
      "outputs": [],
      "source": [
        "def calculate_runnerDicePairArray():\n",
        "  '''Returns an array of shape (6,11,1296) which contains the possible runner locations (encoded as one hot (11,) vectors)\n",
        "   for all the possible 1296 dice rolls, and 6 possible ways to pair the dice'''\n",
        "  #Input:\n",
        "  # Nothing!\n",
        "  #Output:\n",
        "  #  a boolean vector of size (6,11,1296) so that out[i,j,:] is the (11,) boolean vector of the runner locations\n",
        "  #  when the dice roll #i is rolled and choice j is selected\n",
        "  #  This precomputed output is used when computing the runners that can occur in the game\n",
        "\n",
        "  #Create an array of shape (4,6,6,6,6) that contains all possible dice rolls\n",
        "  #  i.e. the entry [:,a,b,c,d] = [a,b,c,d] is 4 dice rolls and a,b,c,d all run from 0 to 5\n",
        "  four_dice_indices = jnp.indices((6,6,6,6)) \n",
        " \n",
        "  #Create an array with all 6 ways to choose 2 out of 4 dice\n",
        "  #  Pairing 0 = choose dice 1 and dice 2\n",
        "  #  Pairing 1 = choose dice 1 and dice 3 \n",
        "  #  ... \n",
        "  #  Pairing 5 = choose dice 3 and dice 4\n",
        "  pairing = jnp.array([[1,1,0,0],[1,0,1,0],[1,0,0,1],[0,1,1,0],[0,1,0,1],[0,0,1,1]])\n",
        "\n",
        "  #Create an array of shape (6,6,6,6,6) which gives the value of the pairing \n",
        "  #  i.e. the (a,b,c,d,p) entry is the value of pairing p when the dice come up a,b,c,d\n",
        "  four_dice_pairings = jnp.einsum(\"iabcd,pi->abcdp\",four_dice_indices,pairing)\n",
        "  \n",
        "  #The same array, but of shape (6,6,6,6,6,11) now where it has been converted to a one hot encoding\n",
        "  #  i.e. (a,b,c,d,p:) is an array of shape (11,) with the one hot encoding of the pairing\n",
        "  four_dice_pairings_one_hot = jnn.one_hot(four_dice_pairings,11)\n",
        "  flattened_but_out_of_order = jnp.reshape(four_dice_pairings_one_hot,(1296,6,11),order='F')\n",
        "  return jnp.transpose( flattened_but_out_of_order, (1,2,0)) #put them in the desired order!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Xrhe6fEGQG"
      },
      "source": [
        "## Helper functions for dealing with runners"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24jMogu5ENbP"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def calculate_player_N_col_claimed(player_col_state):\n",
        "  ''' Calculate player \"scores\" (i.e. number of columns claimed) from the board state'''\n",
        "  #Input:\n",
        "  #  player_col_state = An int array of size (N_players, 11) showing how many entries REMAINING until column is claimed for each player\n",
        "  #Output: \n",
        "  #  An int vector of size (N_players,) showing how many columns each player has claimed. (In normal rules, first to 3 columns wins) \n",
        "  return  jnp.count_nonzero(player_col_state <= 0, axis=1)\n",
        "\n",
        "@jit\n",
        "def calculate_illegal_col(player_col_state):\n",
        "  '''Calculate which columns are legal from the board state (i.e. the unclaimed columns)''' \n",
        "  #Input:\n",
        "  #  player_col_state = An int array of size (N_players, 11) showing how many entries REMAINING until column is claimed for each player\n",
        "  #Output: \n",
        "  #  An boolean vector of size (11,) showing which columns are legal \n",
        "  return jnp.any(player_col_state <= 0, axis=0)\n",
        "\n",
        "@jit\n",
        "def are_runners_legal(runner_col_states, illegal_col, N_MAX_RUNNERS=3):\n",
        "  '''Checks if a batch of runner states are legal or not'''\n",
        "  #Input:\n",
        "  #  runner_col_states = an int vector of size (N,11) of runner positions\n",
        "  #  illegal_col = a boolean vector of size (11,) with which columns are illegal\n",
        "  #Output:\n",
        "  #  a boolean vector of size (N,) with which of the runner_col_states are legal\n",
        "\n",
        "  #Number of runners is legal iff there are <=N_MAX_RUNERS runners active:\n",
        "  are_number_of_runners_legal = (jnp.count_nonzero(runner_col_states,axis=1) <= N_MAX_RUNNERS)\n",
        "\n",
        "  #Check if all the runners are in legal columns\n",
        "  #  In each column, either illegal_column must be 0 OR runners must be 0\n",
        "  illegal_col_or_runner_is_0 = jnp.logical_or(runner_col_states == 0, illegal_col == False)\n",
        "  #  This must happen in every single column\n",
        "  are_runners_in_legal_col = jnp.all(illegal_col_or_runner_is_0,axis=1) \n",
        "  \n",
        "  return jnp.logical_and(are_number_of_runners_legal,are_runners_in_legal_col)\n",
        "\n",
        "DicePairArray = calculate_runnerDicePairArray()\n",
        "@jit\n",
        "def generate_all_choices_and_legality(dice_num,player_col_state,runner_col_state, N_MAX_RUNNERS=3): \n",
        "  illegal_col = calculate_illegal_col(player_col_state)\n",
        "  #print(\"illegal_col\", jnp.shape(illegal_col))\n",
        "  '''Computes out ALL the possible moves based on the dice and \n",
        "  whether or not they are legal based on the current state and dice'''\n",
        "  #  In this version, the input is the dice_num (which is a number in [0,1295]) and \n",
        "  #  the array DiceArray are assumed to exists\n",
        "  #  which is caluclated with the DiceArray function\n",
        "  #Calculate all the 9 possible moves of playing both pairs (i.e. double) and with any single pair\n",
        "  # (We will work out which are legal moves afterwards!)\n",
        "\n",
        "  #Use the dice_num to lookup the runner possibilities from DiceArray\n",
        "  dice_sums_with_1_cols = DicePairArray[0:3,:,dice_num]\n",
        "  dice_sums_without_1_cols = DicePairArray[5:2:-1,:,dice_num]\n",
        "\n",
        "  #print(\"dice_sums_with_1_cols\", jnp.shape(dice_sums_with_1_cols)) \n",
        "  #print(\"runner_col_state\", jnp.shape(runner_col_state))\n",
        "  #This 5:2:-1 gets the pairings in reverse order so that they are complentary to the pairings from dice_sums_with_1\n",
        "  \n",
        "\n",
        "  double_runner_choices = runner_col_state + dice_sums_with_1_cols + dice_sums_without_1_cols\n",
        "  single_runner_choices_with_1 = runner_col_state + dice_sums_with_1_cols \n",
        "  single_runner_choices_without_1 = runner_col_state + dice_sums_without_1_cols\n",
        "\n",
        "  #print(\"double_runner_choices\",jnp.shape(double_runner_choices))\n",
        "\n",
        "  #Compute if the choices with both pairing played (i.e. double) are legal\n",
        "  are_double_runners_legal = are_runners_legal(double_runner_choices,illegal_col, N_MAX_RUNNERS)\n",
        "  #print(\"are_double_runners_legal\",jnp.shape(are_double_runners_legal))\n",
        "  #print(are_double_runners_legal)\n",
        "  are_double_runners_illegal = jnp.logical_not(are_double_runners_legal)\n",
        "\n",
        "\n",
        "  #The moves with a single pair are only legal if the corresponding move with both pairs is illegal \n",
        "  #  (i.e. its legal to play only one pair iff after you play it, playing the next move is not legal)\n",
        "  #  This means we can compute if they are legal on their own first and then\n",
        "  #  logical_and it with the double runners\n",
        "\n",
        "  #  first check if they would be ok on their own.\n",
        "  are_single_runners_with_1_ok = are_runners_legal(single_runner_choices_with_1,illegal_col, N_MAX_RUNNERS)\n",
        "  are_single_runners_without_1_ok = are_runners_legal(single_runner_choices_without_1,illegal_col, N_MAX_RUNNERS)\n",
        "\n",
        "  #  then we logical and it with the double runners to only legalize these moves if playing both was illegal\n",
        "  are_single_runners_with_1_legal = jnp.logical_and(are_double_runners_illegal,are_single_runners_with_1_ok)\n",
        "  are_single_runners_without_1_legal = jnp.logical_and(are_double_runners_illegal,are_single_runners_without_1_ok)\n",
        "  #print(\"ok!\")\n",
        "  #Combine everything together to be outputed\n",
        "  #all_runner_choices = jnp.row_stack()\n",
        "  all_runner_choices = jnp.row_stack([double_runner_choices,single_runner_choices_with_1,single_runner_choices_without_1]) \n",
        "  #print(\"all_runner_choices\", jnp.shape(all_runner_choices))\n",
        "  all_runner_choices_legal = jnp.concatenate([are_double_runners_legal, are_single_runners_with_1_legal, are_single_runners_without_1_legal])\n",
        "  #print(\"all_runner_choices_legal\", jnp.shape(all_runner_choices_legal))\n",
        "\n",
        "  return all_runner_choices, all_runner_choices_legal\n",
        "\n",
        "@jit\n",
        "def update_player_col_state(active_player_index, player_col_state, runner_col_state):\n",
        "  '''Move a players peices forward by the amount on the runners \n",
        "    (This is called when a player bank's their runners and ends their turn by choice)''' \n",
        "  #Input:\n",
        "  #  active_player_index = index of whose turn it is\n",
        "  #  player_col_state = int array of size (N_player, 11) with squares remaining in each column\n",
        "  #  runner_col_state = int vector of size (11,) with runner locations\n",
        "  #Output:\n",
        "  #  An updated version of player_col_state where the positions have been moved up by the runners.\n",
        "\n",
        "  #All we have to do is a subtraction, but ensure that we don't go below zero\n",
        "  updated_active_player_col_state = jnp.clip(player_col_state[active_player_index] - runner_col_state, 0, None)\n",
        "  #print(\"updated col state\", jnp.shape(updated_active_player_col_state))\n",
        "  #ans = player_col_state.at[active_player_index].set(updated_active_player_col_state)\n",
        "  #print(\"ans\", jnp.shape(ans))\n",
        "  return player_col_state.at[active_player_index].set(updated_active_player_col_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SkJvX0yLIup"
      },
      "source": [
        "## Helper Functions for AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu_FS0HHLLg2"
      },
      "outputs": [],
      "source": [
        "#This function also assumes that the DicePairArray global variable has been calculated already\n",
        "@jit\n",
        "def prob_to_miss_targets(targets):\n",
        "  '''Compute the probability to miss a list of target cols'''\n",
        "  #Input:\n",
        "  #  targets = a boolean array of shape (11,) with which are targets\n",
        "  #Output:\n",
        "  #  A real number with the probability to miss all the targets from targets when rolling 4 dice and pairing them\n",
        "  hit_target = jnp.einsum(\"abp,b->pa\",DicePairArray,targets)\n",
        "  any_hit_target = jnp.any(hit_target > 0, axis=1)\n",
        "\n",
        "  #Count the number of times we get a hit!\n",
        "  number_of_dice_rolls_that_hit_target = jnp.count_nonzero(any_hit_target)\n",
        "  return (1296- number_of_dice_rolls_that_hit_target)/1296\n",
        "\n",
        "@jit\n",
        "def cant_stop_bust_probability(runner_col,illegal_col):\n",
        "  #Purpose:\n",
        "  #  Compute the bust_probability if we were to roll again in Can't Stop\n",
        "  #Input:\n",
        "  #  runner_col = an array of shape (11,) of integers with the runner locations\n",
        "  #  illegal_col = an array of shape (11,) of boolean with which columns are illegal to play in \n",
        "  #NOTE:\n",
        "  #  We assume N_Max_Runners = 3 for this one!\n",
        "\n",
        "  N_Max_Runners = 3\n",
        "\n",
        "  runner_loc = (runner_col > 0)\n",
        "\n",
        "  num_runners = jnp.sum(runner_loc) # calculate runners by counting non-zero indices\n",
        "\n",
        "  #set the target_columns that we will not bust if we hit\n",
        "  # -the runner locations are always safe\n",
        "  # -if num_runner<N_Max_Runners, the non-illegal columns are also safe so we add these o\n",
        "  \n",
        "  target_columns = jnp.logical_or(runner_loc, (num_runners < N_Max_Runners)*(jnp.logical_not(illegal_col)))\n",
        "  \n",
        "  #if num_runners >= N_Max_Runners:\n",
        "  #  target_columns = runner_col\n",
        "  #else:\n",
        "  #  target_columns = jnp.logical_or(runner_col, 1-illegal_col)\n",
        "\n",
        "  return prob_to_miss_targets(target_columns) # calculate the chance to miss playable columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3TDpEmwAUV1"
      },
      "source": [
        "## Three simple AIs\n",
        "\n",
        "Note that the AIs always return a tuple choice_index, roll_again \n",
        "\n",
        "choice_index = a number 0-8 indicating which choice they want to make \n",
        "\n",
        "roll_again = a boolean of whether or not they want to roll again "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDu9M2JauI-u"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def pure_random_AI(active_player_index, player_col_state, choices, legal, random_key):\n",
        "  '''An AI that makes all choices purely at random.'''\n",
        "  #Input:\n",
        "  #  active_player_index = An int with whose turn it currently is (which player the AI is playing for)\n",
        "  #  player_col_state = An int array of size (N_players, 11) showing how many entries REMAINING until column is claimed for each player\n",
        "  #  choices = An array of size (9,11) with the 9 possible choices available to the player\n",
        "  #  legal = An array of size (9,) with whether or not each of the 9 choices are legal\n",
        "  #  N_Col_To_Win, N_Max_Runners = Integers that can specify variants of the game rules \n",
        "  #Output: A tupl (choice_index, roll_again)\n",
        "  #  1st entry: choice_index = An integer in [0,8] with which choice is to be played\n",
        "  #             (Note, you must make sure the index you play is legal!)\n",
        "  #  2nd entry: roll_again = A boolean on whether or not to roll again \n",
        "  \n",
        "  #To get the unique choices you can do jnp.unique(choices[legal==True],axis=0)\n",
        "\n",
        "  keys =  jrandom.split(random_key)\n",
        "  \n",
        "  random_scores = jnp.abs( jax.random.normal(keys[0], jnp.shape(legal)) )  \n",
        "  choice_index = jnp.argmax(legal*random_scores,axis=0)  #Since all random_scores have the same distribution, this is a random legal choice\n",
        "\n",
        "  random_scores = jax.random.normal(keys[1], (2,) )\n",
        "  roll_again = jnp.argmax(random_scores,axis=0) #choose to roll again randomly!\n",
        "  \n",
        "  return choice_index, roll_again\n",
        "\n",
        "@jit\n",
        "def random_timid_AI(active_player_index, player_col_state, choices, legal, random_key):\n",
        "  '''An AI that chooses what to choose (somewhat) randomly, and then is timid about rolling again or not'''\n",
        "\n",
        "  #Inputs/Outputs same as for the pure_random_AI\n",
        "  \n",
        "  #Choose the choice randomly\n",
        "  #Rolls again if it has <=2 runners and doesnt roll again if it has 3 runners already\n",
        "\n",
        "  random_scores = jnp.abs( jax.random.normal(random_key, (9,) ) )  \n",
        "  choice_index = jnp.argmax(legal*random_scores)  #Since all random_scores have the same distribution, this is a random legal choice\n",
        "\n",
        "  N_runners = jnp.count_nonzero( choices[choice_index] )\n",
        "  roll_again = (N_runners <= 2) \n",
        "\n",
        "  return choice_index, roll_again #silly AI picks the first choice and stops rolling again\n",
        "\n",
        "@jit\n",
        "def runner_weights_AI(active_player_index, player_col_state, choices, legal, random_key):\n",
        "  '''An AI that uses the position of the runners to make choices, taking into account that some columns are better than others'''\n",
        "  #Inputs/Ouputs same as other AIs\n",
        "\n",
        "  column_weights = jnp.array([6,5,4,3,2,1,2,3,4,5,6]) #The weights used for each column\n",
        "  reroll_threshold = 13.0 #Reroll if the score is lower than this, otherwise stay\n",
        "\n",
        "  scores = (choices @ column_weights) #Calculate the score for each of the choices\n",
        "  \n",
        "  choice_index = jnp.argmax( legal*scores  ) #Choose the best one of the legal options \n",
        "\n",
        "  N_runners = jnp.count_nonzero( choices[choice_index] ) #Number of runners in our choice\n",
        "\n",
        "  #Reroll if we have only 1 runner or if we are less than the reroll threshold\n",
        "  roll_again =  jnp.logical_or(N_runners <= 1, scores[choice_index] < reroll_threshold) \n",
        "\n",
        "  return choice_index, roll_again\n",
        "\n",
        "\n",
        "# benchmark AIs\n",
        "random_timid_AI_vmap = jax.jit(jax.vmap( random_timid_AI, in_axes=(None,2,2,1,0), out_axes=0 ))\n",
        "runner_weights_AI_vmap = jax.jit(jax.vmap( runner_weights_AI, in_axes=(None,2,2,1,0), out_axes=0 ))\n",
        "pure_random_AI_vmap = jax.jit(jax.vmap( pure_random_AI, in_axes=(None,2,2,1,0), out_axes=0 ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS-W-wtMDU7v"
      },
      "source": [
        "# Feature Helper Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the advance probability\n",
        "\n",
        "Here we calculate the probability that we advance runners by one or two positions in each column on any given roll. This is done by creating a (3888, 11) array of the possible choices for all rolls. Then counting the number of 1's and 2's in each columns. This is the frequency that we advance by 1 or 2 in each column. If we advance by 2 then we must have rolled 2 pairs of identical die, so there are only 3 different ways to combine thus we divide by 3 * 1296 to get the probability. If we advance by 1 then we did not roll 2 pairs of identical die, so there are 6 different ways to combine these die, thus we divide by 6 * 1296. This gives us an the probability to advance by 1 in each column.\n",
        "\n",
        "### Purpose\n",
        "\n",
        "This array is used to calculate the true expected advancement of the runners on any given roll. In practice, I hard code this array into my AI so that it doesn't need to be global or recalculated every time.\n",
        "\n",
        "The true expected advancement can be calculated by the following formula:\n",
        "\n",
        "\\begin{align*}\n",
        "  \\mathbb{E}[\\text{R}] = \\text{R} + (\\text{P}[0] + 2\\text{P}[1])((\\text{R} > 0) + (1 - \\text{I}) * (3 - \\text{N_runners})) \\tag{1}\n",
        "\\end{align*}\n",
        "\n",
        "Where R is the runner column state, P[0] is the array of probabilities to advance by 1 in each column, P[1] is the array of probability to advance by 2 in each column, I is an array of illegal columns, and N_runner is the number of runners currently in play."
      ],
      "metadata": {
        "id": "bL-zFlc4Q3vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhqxkpmODTpk",
        "outputId": "02275120-359c-45e2-dfa5-9a84cde0dbeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability to advance by 1 in any column 0.8873456\n",
            "Probability to advance by 2 in any column 0.112654306\n"
          ]
        }
      ],
      "source": [
        "@jit\n",
        "def calc_adv_probs():\n",
        "  '''calculates the probability to advance by 1 or 2 in each column'''\n",
        "  # Input: Nothing\n",
        "  # Ouput: A (2,11) array where [0, :] is an array of probabilities of advancing by 1 in each column\n",
        "  #                       and   [1, :] is an array of probabilities of advancing by 2 in each column\n",
        "\n",
        "  four_dice_indices = jnp.indices((6,6,6,6)) \n",
        "  pairing = jnp.array([[1,1,0,0],[1,0,1,0],[1,0,0,1],[0,1,1,0],[0,1,0,1],[0,0,1,1]])\n",
        "  four_dice_pairings = jnp.einsum(\"iabcd,pi->abcdp\",four_dice_indices,pairing)\n",
        "  four_dice_pairings_one_hot = jnn.one_hot(four_dice_pairings,11)\n",
        "\n",
        "  # there are 3 possible choices in each roll, find the gained progress for all choices in every roll\n",
        "  all_combinations = jnp.reshape(jnp.sum(four_dice_pairings_one_hot[:,:,:,:,jnp.array([[0, 5], [1, 4], [2,3]])], axis=5), (3888, 11))\n",
        "\n",
        "  # count num of ways to advance by 1 or 2 in each column\n",
        "  num_adv_1_col = jnp.count_nonzero(all_combinations[:][:] == jnp.array([1,1,1,1,1,1,1,1,1,1,1]), axis=0)/7776 # (6 * 1296) # 6 different combinations get same result\n",
        "  num_adv_2_col = jnp.count_nonzero(all_combinations[:][:] == jnp.array([2,2,2,2,2,2,2,2,2,2,2]), axis=0)/3888 # (3 * 1296) # 3 different combinations get same result \n",
        "\n",
        "  # turn into probabilty and return\n",
        "  return jnp.stack([num_adv_1_col, num_adv_2_col])\n",
        "\n",
        "def calc_adv_probs_test():\n",
        "  '''Checks if the probabilities add to 1 to satisfy probability axiom'''\n",
        "  adv_prob = calc_adv_probs()\n",
        "\n",
        "  # probability should add to 1\n",
        "  assert(jnp.isclose(jnp.sum(adv_prob[0] + adv_prob[1]), 1))\n",
        "  print(\"Probability to advance by 1 in any column\", jnp.sum(adv_prob[0]))\n",
        "  print(\"Probability to advance by 2 in any column\", jnp.sum(adv_prob[1]))\n",
        "\n",
        "calc_adv_probs_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buH2WaFlcBmB"
      },
      "source": [
        "# Train AI\n",
        "\n",
        "This AI just has a weights parameter so that it can be modified while training without needing a global variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2SYVn43b_Em"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def Train_AI(w, active_player_index, player_col_state, choices, legal):\n",
        "  '''An AI function using some weights w which are assumed to be a global variable'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - whose turn it is\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # choices - an array of possible choices that the AI can make\n",
        "  # legal - an array of which choices are legal\n",
        "  #Output:\n",
        "  # best_choice_index - if there is a legal choice, this is the legal choice that gives the highest estimated probability to win;\n",
        "  #                     if there is no legal choice it gives the illegal choice with the highest estimated probability to win.\n",
        "  # roll_again - choice whether to roll again or stay - this is whatever choice gives the highest estimated probability to win.\n",
        "\n",
        "  # calculate N columns claimed and the illegal columns to be used in the AI\n",
        "  player_N_col_claimed = calculate_player_N_col_claimed(player_col_state)\n",
        "  illegal_col = calculate_illegal_col(player_col_state)\n",
        "\n",
        "  # this passes all the choices into the value function at once\n",
        "  # the result is a vector of shape (9,) with the value of each of the 9 options\n",
        "  all_vals = Train_v_func(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, choices)\n",
        "  \n",
        "  # take the maximum but only overthose that are legal!\n",
        "  # (multuplying by \"legal\" sets the value of any illegal moves to 0)\n",
        "  best_choice_index = jnp.argmax(all_vals * legal)\n",
        "\n",
        "  # deciding whether or not to roll again (uses the Q function)\n",
        "  # compute the value for rolling again and staying from that state.\n",
        "  runner_col_state = choices[best_choice_index]\n",
        "  q_roll_again_val = Train_q_roll_again(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state)\n",
        "  q_stay_val = Train_q_stay(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state)\n",
        "\n",
        "  # checks if the value of rolling again is higher than the value of staying\n",
        "  # in this case we should roll again\n",
        "  roll_again = q_roll_again_val > q_stay_val\n",
        "    \n",
        "  return best_choice_index, roll_again\n",
        "\n",
        "def reflect_column_weights(w):\n",
        "  '''Takes in 6 weights and reflects them around the middle column to cover all 11 columns'''\n",
        "  #Input: \n",
        "  # w - array of shape (6,) of the weights to reflect\n",
        "  #Output:\n",
        "  # array of shape (11,) of the reflected weights around the middle column\n",
        "\n",
        "  reflected_w = jnp.zeros(11)\n",
        "  reflected_w = reflected_w.at[0:6].set(w[0:6])\n",
        "  reflected_w = reflected_w.at[6:12].set(w[4::-1])\n",
        "  return reflected_w\n",
        "\n",
        "@jit\n",
        "def Train_v_func(w,active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state):\n",
        "  '''Value function for the AI. Estimates the probability of the active player to win. (i.e. the value of the game where +1 for a win and 0 for a loss)'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - whose turn it is\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # player_N_col_claimed - the number of columns each player has claimed\n",
        "  # illegal_col - the current columns that cannot be played in\n",
        "  # runner_col_state - the distance runner has travelled in each column\n",
        "  #Output:\n",
        "  # The probability to win in the given state.\n",
        "\n",
        "  #Divide the weights w into three categories\n",
        "  runner_w = w[0:6] # weights for runner location features\n",
        "  player_col_w = w[6:12] # the amount we have advanced in each column\n",
        "  enemy_col_w = w[12:18] # the amount the enemy has advanced in each column\n",
        "  player_col_claim_w = w[18:24] # weights for the columns that we have claimed\n",
        "  enemy_col_claim_w = w[24:30] # weights for the columns that the enemy has claimed\n",
        "  player_N_col_claimed_w = w[30] # weights for number of columns we have claimed\n",
        "  enemy_N_col_claimed_w = w[31] # weights for the number of columns the enemy has claimed\n",
        "  affine_w = w[32] # this weight just allows for affine functions\n",
        "\n",
        "  # we use symmetry to reduce number of weights, so here we reflect the weights\n",
        "  # so they cover all 11 columns.\n",
        "  runner_w = reflect_column_weights(runner_w)\n",
        "  player_col_w = reflect_column_weights(player_col_w)\n",
        "  enemy_col_w = reflect_column_weights(enemy_col_w)\n",
        "  player_col_claim_w = reflect_column_weights(player_col_claim_w)\n",
        "  enemy_col_claim_w = reflect_column_weights(enemy_col_claim_w)\n",
        "\n",
        "  score = jnp.inner(runner_w, runner_col_state)\n",
        "\n",
        "  #We look only at the difference in player locations here\n",
        "  column_lengths = jnp.array([3, 5, 7, 9, 11, 13, 11, 9, 7, 5, 3])\n",
        "  player_col = (column_lengths - player_col_state[active_player_index])*(1 - illegal_col)\n",
        "  enemy_col = (column_lengths - player_col_state[1 - active_player_index])*(1 - illegal_col)\n",
        "\n",
        "  score += jnp.inner(player_col_w, player_col)\n",
        "  score -= jnp.inner(enemy_col_w, enemy_col)\n",
        "  \n",
        "  #Here we look only at the difference in the N col climaed between the two players\n",
        "  player_col_claimed = jnp.where(player_col_state[active_player_index] < 1, 1, 0)\n",
        "  enemy_col_claimed = jnp.where(player_col_state[1 - active_player_index] < 1, 1, 0)\n",
        "\n",
        "  # calculates the precentage of the column we have claimed\n",
        "\n",
        "  score += player_N_col_claimed[active_player_index] * player_N_col_claimed_w\n",
        "  score -= player_N_col_claimed[1 - active_player_index] * enemy_N_col_claimed_w\n",
        "\n",
        "  score += jnp.inner(player_col_claim_w, player_col_claimed)\n",
        "  score -= jnp.inner(enemy_col_claim_w, enemy_col_claimed)\n",
        "\n",
        "  score += affine_w\n",
        "\n",
        "  #Apply a sigmoid to the score so that the value function is always between 0 and 1\n",
        "  return jnn.sigmoid(score)\n",
        "\n",
        "@jit\n",
        "def Train_q_roll_again(w,active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state):\n",
        "  '''Find the approximated value for rolling again in terms of the value function v'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - whose turn it is\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # player_N_col_claimed - the number of columns each player has claimed\n",
        "  # illegal_col - the current columns that cannot be played in\n",
        "  # runner_col_state - the distance runner has travelled in each column\n",
        "  #Output:\n",
        "  # An estimate of the probability to win given that we choose to roll again.\n",
        "  \n",
        "  # compute the score if we would bust\n",
        "  zero_runner = jnp.zeros(11, dtype=jnp.dtype('u1')) \n",
        "  bust_value = 1 - Train_v_func(w, 1 - active_player_index, player_col_state, player_N_col_claimed, illegal_col, zero_runner) \n",
        "\n",
        "  # calculates the probabilities of advancing 1 or 2 in each column\n",
        "  #adv_probs = calc_adv_probs()\n",
        "  # i hard code this!\n",
        "  adv_prob = jnp.array([[0.02700617, 0.05246913, 0.07638889, 0.09876543, 0.11959876, 0.13888888, 0.11959876, 0.09876543, 0.07638889, 0.05246913, 0.02700617], [0.0007716, 0.00308642, 0.00694444, 0.01234568, 0.01929012, 0.02777778, 0.01929012, 0.01234568, 0.00694444, 0.00308642, 0.0007716]])\n",
        "\n",
        "  # compute the score if we would not bust\n",
        "  N_runner = jnp.count_nonzero(runner_col_state)\n",
        "\n",
        "  # calculates the expected runner col state as in equation (1)\n",
        "  advance_runner = runner_col_state + (1 * adv_prob[0] + 2 * adv_prob[1]) * ((runner_col_state > 0) + (1 - illegal_col) * (3 - N_runner))\n",
        "\n",
        "  # the value of the expected runner col state\n",
        "  advance_value = Train_v_func(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, advance_runner)\n",
        "\n",
        "  # find the probability of busting\n",
        "  p_bust = cant_stop_bust_probability(runner_col_state,illegal_col)\n",
        "\n",
        "  # the answer is the convex combination of the bust value and advance value using p_bust\n",
        "  return p_bust * bust_value + (1 - p_bust) * advance_value\n",
        "\n",
        "@jit\n",
        "def Train_q_stay(w,active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state):\n",
        "  '''Returns the value (according to the value function v) of staying'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - whose turn it is\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # player_N_col_claimed - the number of columns each player has claimed\n",
        "  # illegal_col - the current columns that cannot be played in\n",
        "  # runner_col_state - the distance runner has travelled in each column\n",
        "  #Output:\n",
        "  # An estimate of the probability to win given that we choose to stay.\n",
        "\n",
        "  # if we stay, the runners advance and we can update our game state\n",
        "  updated_player_col_state = update_player_col_state(active_player_index,player_col_state,runner_col_state) \n",
        "  updated_player_N_col_claimed = calculate_player_N_col_claimed(updated_player_col_state)\n",
        "  updated_illegal_col = calculate_illegal_col(updated_player_col_state)\n",
        "\n",
        "  # the runners will return to zero\n",
        "  zero_runner = jnp.zeros(11, dtype=jnp.dtype('u1')) \n",
        "\n",
        "  # since v_func is estimating the probability of the active player to win,\n",
        "  # if we choose to stay we need to do P(we win) = 1-P(other player wins)\n",
        "  return 1 - Train_v_func(w, 1 - active_player_index, updated_player_col_state, updated_player_N_col_claimed, updated_illegal_col, zero_runner)\n",
        "\n",
        "\n",
        "## AI value function Gradient\n",
        "grad_Train_v_func = jax.jit(jax.grad(Train_v_func, 0))\n",
        "\n",
        "## VMAP AI\n",
        "Train_AI_vmap = jax.jit(jax.vmap(Train_AI, in_axes=(None, None, 2, 2, 1), out_axes=0 ))\n",
        "Train_v_func_vmap = jax.jit(jax.vmap(Train_v_func, in_axes=(None, None, 2, 1, 1, 1), out_axes=0))\n",
        "grad_Train_v_func_vmap=jax.jit(jax.vmap(jax.grad(Train_v_func, 0), in_axes=(None, None, 2, 1, 1, 1), out_axes=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMbl_XPrJ53d"
      },
      "source": [
        "# Training\n",
        "\n",
        "**Method:** I chose to use SARSA for linear function approximation and learned the weights directly on the value function.\n",
        "\n",
        "**State Space:** The state space consists of three parts *(active_player_index, player_col_state, runner_col_state)*.\n",
        "\n",
        "* *active_player_index* - $0$ or $1$.\n",
        "* *player_col_state* - array of shape $(2, 11)$ with the distance for each player to claim each column.\n",
        "* *runner_col_state* - array of shape $(11, )$ with the distance runners have advanced in each column.\n",
        "\n",
        "**Action Space:** \n",
        "\n",
        "* *choice* - number between $0$ and $8$ of the $9$ possible ways to advance runners.\n",
        "* *roll_again* - True if we choose to roll again, False if we choose to stay.\n",
        "\n",
        "**Reward Space:** When transitioning to a terminal state the active player gets a reward of $1$.\n",
        "\n",
        "**Action Selection:** By SARSA, we choose the action through and $ɛ-$greedy selection. We choose a purely random action with probability $ɛ$ and we choose the best action with probability $1 - ɛ$. As we train $ɛ$ will be reduced and should converge to $0$. Throughout training $ɛ$ was updated using the following rule $ɛ = \\frac{0.1}{\\sqrt{i+1}}$.\n",
        "\n",
        "**Learning Rate Selection:** I used a learning rate of $\\alpha = \\frac{0.02}{\\sqrt{i+1}}$ where $i$ is the current iteration. I chose this through checking a bunch of different learning rate. I found that this learning rate produced the best results. I have tried several others but have not seen as much success.\n",
        "\n",
        "**Update Rules:** I have two update rules. One when we are not in a terminal state, and one when we are in a terminal state.\n",
        "\n",
        "- Mid game update rule: $w = w + \\alpha(v_{func}(S') - v_{func}(S))\\Delta v_{func}(S)$\n",
        "- Terminal update rule: $w = w + \\alpha(1 - v_{func}(S))\\Delta v_{func}(S)$\n",
        "\n",
        "The terminal update rule is used when we are in a terminal state, in this case the active player has won the game. Therefore, $v_{func}(S') = 1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SuZR5u5MsNS"
      },
      "source": [
        "### Training Helper Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJjIY4BBSKGw"
      },
      "outputs": [],
      "source": [
        "def epsilon_action(w, player_col_state, choices, legality, random_key, epsilon=0.10):\n",
        "  '''determine if we should choose action greedy, or purely random'''\n",
        "  #Input: \n",
        "  # w - the weights\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # choices - an array of possible choices that the AI can make\n",
        "  # legality - an array of which choices are legal\n",
        "  # random_key - a random key\n",
        "  # epsilon - the probability to choose a purely random action\n",
        "  #Output:\n",
        "  # An estimate of the probability to win given that we choose to stay.\n",
        "\n",
        "  probability_epsilon_event = (np.random.random() < epsilon)\n",
        "  \n",
        "  keys = jrandom.split(random_key)\n",
        "\n",
        "  if probability_epsilon_event:\n",
        "    # Since all random_scores have the same distribution, this is a random legal choice\n",
        "    # choose random action!\n",
        "    random_scores = jnp.abs(jax.random.normal(keys[0], jnp.shape(legality)))  \n",
        "    choice = jnp.argmax(legality * random_scores,axis=0)\n",
        "    roll_again = jrandom.randint(keys[1], jnp.shape(choice), 0, 2)\n",
        "  else:\n",
        "    choice, roll_again = Train_AI(w, 0, player_col_state, choices, legality)\n",
        "\n",
        "  return (choice, roll_again)\n",
        "\n",
        "def update_v_func_mid(w, active_player_index, next_active_player_index, c_state, n_state, learning_rate):\n",
        "  '''Update rule for training on the value function during a transition to a non-terminal state'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - the index of the current player\n",
        "  # next_active_player_index - the index of the current player in the next state\n",
        "  # c_state - tuple of the player_col_state and runner_col_state (as described above) in the current state\n",
        "  # n_state - tuple of the player_col_state and runner_col_state in the next state\n",
        "  # learning_rate - the step size for the update rule\n",
        "  #Output:\n",
        "  # new weights after the update rule\n",
        "\n",
        "  # get other required information\n",
        "  player_N_col_state = calculate_player_N_col_claimed(c_state[0])\n",
        "  illegal_col = calculate_illegal_col(c_state[0])\n",
        "\n",
        "  next_player_N_col_state = calculate_player_N_col_claimed(n_state[0])\n",
        "  next_illegal_col = calculate_illegal_col(n_state[0])\n",
        "\n",
        "  # pack into single tuple for readability\n",
        "  c_state = (w, active_player_index, c_state[0], player_N_col_state, illegal_col, c_state[1])\n",
        "  n_state = (w, next_active_player_index, n_state[0], next_player_N_col_state, next_illegal_col, n_state[1])\n",
        "\n",
        "  # the value of the current state\n",
        "  curr_v_func = Train_v_func(*c_state)\n",
        "\n",
        "  # if the next player is the same, then it is still our turn and the probability to win in the next state is\n",
        "  # given by the value function. If the next player is not the same, then it is not our turn anymore. In this case\n",
        "  # the value of the next state is given by 1 - v_func.\n",
        "  if active_player_index == next_active_player_index:\n",
        "    next_v_func = Train_v_func(*n_state)\n",
        "  else:\n",
        "    next_v_func = 1 - Train_v_func(*n_state)\n",
        "\n",
        "  # the update rule [ w += alpha*(v(s') - v(s))*grad_v(v) ]\n",
        "  delta = next_v_func - curr_v_func\n",
        "  w = w + learning_rate*(delta)*grad_Train_v_func(*c_state)\n",
        "\n",
        "  return w\n",
        "\n",
        "def update_v_func_terminal(w, active_player_index, c_state, learning_rate):\n",
        "  # This is the update rule when the next state would be terminal\n",
        "  # in this case the value is 1.\n",
        "  #Input:\n",
        "  # w - current weights\n",
        "  # active_player_index - the index of the player whose turn it currently is\n",
        "  # c_state - the current state (player_col_state, runner_col_state)\n",
        "  # learning_rate - the learning rate\n",
        "  #Output:\n",
        "  # new weights\n",
        "\n",
        "  # get other required information\n",
        "  player_N_col_state = calculate_player_N_col_claimed(c_state[0])\n",
        "  illegal_col = calculate_illegal_col(c_state[0])\n",
        "\n",
        "  # pack into single tuple for readability\n",
        "  c_state = (w, active_player_index, c_state[0], player_N_col_state, illegal_col, c_state[1])\n",
        "\n",
        "  # the update rule\n",
        "  delta = 1 - Train_v_func(*c_state)\n",
        "  w = w + learning_rate*(delta)*grad_Train_v_func(*c_state)\n",
        "\n",
        "  return w\n",
        "  \n",
        "def roll_and_get_choices(key, player_col_state, runner_col_state, N_MAX_RUNNERS=3):\n",
        "  dice_num =  int(jax.random.randint(key, (1,), 0,1296)) #random.randint(0,1295)\n",
        "  runner_choices, runner_legal = generate_all_choices_and_legality(dice_num, player_col_state, runner_col_state, N_MAX_RUNNERS)\n",
        "\n",
        "  return runner_choices, runner_legal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnzM78ePMa7H"
      },
      "source": [
        "### Simulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR_wNg2w3WON"
      },
      "outputs": [],
      "source": [
        "def train_ai_sim(w, key, enemy, learning_rate=5, epsilon=0.1, verbose=False, N_PLAYERS=2, N_COL_TO_WIN=5, N_MAX_RUNNERS=3, PLAYER_COL_STATE_INIT=[3,5,7,9,11,13,11,9,7,5,3]):\n",
        "  # initialize the game state\n",
        "  player_col_state = jnp.tile(jnp.array(PLAYER_COL_STATE_INIT, dtype=jnp.dtype('i1')), (N_PLAYERS, 1))\n",
        "  runner_col_state = jnp.zeros(11, dtype=jnp.dtype('u1'))\n",
        "  active_player_index = random.randint(0,N_PLAYERS-1)\n",
        "  \n",
        "  game_in_progress = True\n",
        "  while game_in_progress:\n",
        "\n",
        "    roll_again_state = not_busted_state = True\n",
        "    while roll_again_state:\n",
        "      # roll die\n",
        "      key, subkey_1, subkey_2 = jax.random.split(key, 3)\n",
        "      runner_choices, runner_legal = roll_and_get_choices(subkey_1, player_col_state, runner_col_state)\n",
        "\n",
        "      # check if we have busted\n",
        "      any_legal_choices = jnp.any(runner_legal)\n",
        "      not_busted_state = not_busted_state and any_legal_choices\n",
        "\n",
        "      # if not busted choose an action\n",
        "      if not_busted_state:\n",
        "        # if it is our turn then we use epsilon greedy, otherwise we use the enemy AI\n",
        "        if active_player_index == 0:\n",
        "          choice_index, roll_again_state = epsilon_action(w, player_col_state, runner_choices, runner_legal, key, epsilon=epsilon)\n",
        "        else:\n",
        "          choice_index, roll_again_state = enemy(active_player_index, player_col_state, runner_choices, runner_legal, subkey_2)\n",
        "\n",
        "        # if we choose an illegal action we have busted!\n",
        "        not_busted_state = not_busted_state and runner_legal[choice_index]\n",
        "\n",
        "        # get next runner col state\n",
        "        next_runner_col_state = runner_choices[choice_index]\n",
        "\n",
        "      # if you are busted you are not allowed to roll again!\n",
        "      roll_again_state = roll_again_state and not_busted_state\n",
        "    \n",
        "      # we update the value function with only the change in the runner column\n",
        "      c_state = (player_col_state, runner_col_state)\n",
        "      n_state = (player_col_state, next_runner_col_state)\n",
        "      w = update_v_func_mid(w, active_player_index, active_player_index, c_state, n_state, learning_rate)\n",
        "\n",
        "      runner_col_state = next_runner_col_state\n",
        "\n",
        "    # end of players turn, calculate the next state\n",
        "\n",
        "    # if we bust then we should not advance player col\n",
        "    next_runner_col_state = runner_col_state * not_busted_state\n",
        "    next_player_col_state = update_player_col_state(active_player_index, player_col_state, next_runner_col_state)\n",
        "\n",
        "    # at the start of the next turn, runners should be zero and we go to next player\n",
        "    next_runner_col_state = jnp.zeros(11, dtype=jnp.dtype('u1'))\n",
        "    next_active_player_index = (active_player_index + 1) % N_PLAYERS\n",
        "\n",
        "    # check if game is still in progress\n",
        "    player_N_col_claimed = calculate_player_N_col_claimed(next_player_col_state)\n",
        "    game_in_progress = not jnp.any(player_N_col_claimed >= N_COL_TO_WIN)\n",
        "\n",
        "    if game_in_progress:\n",
        "      # update value function when we switch turn\n",
        "      c_state = (player_col_state, runner_col_state)\n",
        "      n_state = (next_player_col_state, next_runner_col_state)\n",
        "      w = update_v_func_mid(w, active_player_index, next_active_player_index, c_state, n_state, learning_rate)\n",
        "\n",
        "      # update the current state\n",
        "      player_col_state = next_player_col_state\n",
        "      active_player_index = next_active_player_index\n",
        "      runner_col_state = next_runner_col_state\n",
        "\n",
        "  # give reward if we win!\n",
        "  c_state = (player_col_state, runner_col_state)\n",
        "  w = update_v_func_terminal(w, active_player_index, c_state, learning_rate)\n",
        "\n",
        "  return player_N_col_claimed >= N_COL_TO_WIN , w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHguQIpp7qXo"
      },
      "outputs": [],
      "source": [
        "def train_ai(weights, n_runs, enemy, verbose=True):\n",
        "  '''Train the AI'''\n",
        "  #Input:\n",
        "  # weights - the weights\n",
        "  # n_runs - the number of runs\n",
        "  # enemy - the enemy AI to train again\n",
        "  # verbose - optional parameter, this will make the simulator output what is happening\n",
        "  #Output:\n",
        "  # The new weights\n",
        "\n",
        "  # generate a new random key seeded with time\n",
        "  key = jrandom.PRNGKey(int(time.time()))\n",
        "\n",
        "  # initialize the score to 0s\n",
        "  score = jnp.zeros(2)\n",
        "  for i in jnp.arange(n_runs):\n",
        "\n",
        "    # these are the best hyperparameters that I could find\n",
        "    learning_rate=0.02/jnp.sqrt(i+1)\n",
        "    epsilon=0.1/jnp.sqrt(i+1)\n",
        "\n",
        "    # Every 10 games we output the current run, the score, learning rate, epsilon, and new weights.\n",
        "    if (i % 100 == 0):\n",
        "      print(f\"Run {i+1} of {n_runs}\")\n",
        "      print(f\"Score: {score}\")\n",
        "      print(f\"Learning Rate: {learning_rate}\")\n",
        "      print(f\"Epsilon: {epsilon}\")\n",
        "      print(f\"Weights: {weights}\")\n",
        "\n",
        "    # split the key, run the simulator, and update the score\n",
        "    key, _ = jrandom.split(key)\n",
        "    wins, weights = train_ai_sim(weights, key, enemy, learning_rate=learning_rate, epsilon=epsilon, verbose=verbose)\n",
        "    score += wins\n",
        "\n",
        "  # Print the final score and the final weights.\n",
        "  print(f\"After {n_runs} games, first player wins {100*score[0]/n_runs:.2f}% of the time\")\n",
        "  print(f\"New weights: {weights}\")\n",
        "\n",
        "  return weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.set_printoptions(linewidth=100)\n",
        "\n",
        "w = jnp.ones(33)*0.1\n",
        "new_w = train_ai(w, 10000, runner_weights_AI, verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R03A_DxKJ183",
        "outputId": "afbb039d-cd1d-49c8-a0ed-856856c18749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 of 10000\n",
            "Score: [0. 0.]\n",
            "Learning Rate: 0.019999999552965164\n",
            "Epsilon: 0.10000000149011612\n",
            "Weights: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
            " 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECjnr9B6yzl7"
      },
      "source": [
        "# Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcQwQy4oz_D5"
      },
      "outputs": [],
      "source": [
        "def simulate_game_parr(Player_AI, Verbose = False, random_key=None, Starting_Player=0, N_PARR=100, N_PLAYERS=2, N_COL_TO_WIN=5, N_MAX_RUNNERS=3, PLAYER_COL_STATE_INIT=None):\n",
        "  '''Run a simulation of the game Can't Stop! running N_PARR games in parrallel'''\n",
        "  #Note that the TURN order for all the games is the same, so who is the starting player matters! \n",
        "\n",
        "  #Input:\n",
        "  #   random_key = A jax random key used to make all the dice rolls for the game\n",
        "  #   Player_AI = List with the functions for player AIs\n",
        "  #   Verbose = whether or not to print out a play-by-play of the game\n",
        "  #Output:\n",
        "  #  An array of shape (N_players,) with a 1 at the player who won\n",
        "  \n",
        "  #Initialize game state\n",
        "  #Initialize game state\n",
        "  if PLAYER_COL_STATE_INIT == None:\n",
        "    player_col_state = jnp.tile(jnp.array([3,5,7,9,11,13,11,9,7,5,3],dtype=jnp.dtype('i1')),(N_PARR, N_PLAYERS, 1))\n",
        "  else:\n",
        "    player_col_state = jnp.tile( PLAYER_COL_STATE_INIT, (N_PARR, 1, 1))  \n",
        "  \n",
        "  player_col_state = jnp.transpose(player_col_state, (1,2,0)) #Move it so the N_PARR dimension is LAST\n",
        "  \n",
        "  if random_key == None:\n",
        "    random_key = jrandom.PRNGKey(int(time.time()))\n",
        "  \n",
        "  #Record which games are in progress (to make sure we don't mess with those games)\n",
        "  game_in_progress = jnp.ones(N_PARR, dtype=bool)\n",
        "  \n",
        "  #Note that the player whose turn it is the SAME accross all games\n",
        "  #This means its improtant to run the function more than once so there is no bias towards whoever plays first\n",
        "  active_player_index = Starting_Player - 1 \n",
        "  \n",
        "  #Main loop that goes until all games are over\n",
        "\n",
        "  turn_num = 0\n",
        "  roll_num = 0\n",
        "  while jnp.any(game_in_progress): #This will loop until the game ends \n",
        "    turn_num += 1\n",
        "    \n",
        "    #Update whose turn it is\n",
        "    active_player_index = (active_player_index + 1) % N_PLAYERS\n",
        "    \n",
        "    if Verbose : print(\"Player \",active_player_index,\":\") \n",
        "    #if Verbose : print(\"--Player Column State: \\n\",player_col_state)\n",
        "\n",
        "    #Reset runners and \"busted\"/\"roll again\" flags\n",
        "    runner_col_state = jnp.zeros( (11,N_PARR) ,dtype=jnp.dtype('u1'))\n",
        "\n",
        "    #roll_again_state and not_busted_state keep track of whether or not the player has\n",
        "    #chosen to roll again and/or busted yet \n",
        "    #This is vector of length N_PARR and is only true for games still in progress\n",
        "    roll_again_state = game_in_progress\n",
        "    not_busted_state = game_in_progress \n",
        "\n",
        "    #Loop while player is chooising to rolling on their turn\n",
        "    while jnp.any( roll_again_state ):\n",
        "      roll_num += 1\n",
        "\n",
        "      #This represents a random dice roll for each N_PARR simulation \n",
        "      # (1296 = 6**4 is the number of possibilities for 4 6-sided dice)\n",
        "      random_key, subkey_1, subkey_2 = jax.random.split(random_key,3)\n",
        "      dice_num = jrandom.randint(subkey_1, (N_PARR,) , 0,1296)\n",
        "      \n",
        "      if Verbose : print(\"----DiceNums: \",dice_num) \n",
        "\n",
        "      #Generate all 9 possible runner choices and whether or not they are legal\n",
        "      runner_choices, runner_legal = generate_all_choices_and_legality(dice_num,player_col_state,runner_col_state, N_MAX_RUNNERS)\n",
        "      \n",
        "      #Update the busted state: you are only not busted if you have at least one legal choice\n",
        "      any_legal_choices = jnp.any(runner_legal==True,axis=0)\n",
        "\n",
        "      #To stay in the game, you must be in the game already and have legal choices\n",
        "      # OR you chose to stop rolling before this turn\n",
        "      chose_to_stop_rolling_or_legal_choices = jnp.logical_or(any_legal_choices, jnp.logical_not(roll_again_state))\n",
        "      not_busted_state = jnp.logical_and(not_busted_state, chose_to_stop_rolling_or_legal_choices)\n",
        "\n",
        "      #Send the choices to the AI to choose from\n",
        "      #Note that we run this even for ones where we've already busted (we just make sure to do nothing with this data) \n",
        "      active_player_AI = Player_AI[active_player_index]\n",
        "      \n",
        "      parr_random_keys = jax.random.split(subkey_2, N_PARR)\n",
        "      choice_index, new_roll_again_state = active_player_AI(active_player_index, player_col_state, runner_choices, runner_legal, parr_random_keys)\n",
        "\n",
        "      #Ensure the choice you made was legal. If you make an illegal choice we count it as if you busted.\n",
        "      choice_was_legal = runner_legal[choice_index, jnp.arange(N_PARR)]\n",
        "      chose_to_stop_rolling_or_choice_was_legal = jnp.logical_or(choice_was_legal, jnp.logical_not(roll_again_state))\n",
        "      not_busted_state = jnp.logical_and(not_busted_state, chose_to_stop_rolling_or_choice_was_legal)\n",
        "\n",
        "      #Find the runner position if they would advance according to the choices, choosing choice_index[i] for simulation number i\n",
        "      new_runner_col_state = jnp.transpose(runner_choices[choice_index,:,jnp.arange(N_PARR)], (1,0) )\n",
        "\n",
        "      #Update the runners to these new positions only if you were still rolling!\n",
        "      # If you don't meet this criteria, then your roll doesnt count and runners stay where they are\n",
        "      runner_col_state = jnp.where( roll_again_state, new_runner_col_state, runner_col_state)\n",
        "      \n",
        "      #runner_col_state = jnp.where( jnp.logical_and(roll_again_state,not_busted_state), new_runner_col_state, runner_col_state)\n",
        "\n",
        "      #Update roll_again_state for next round.\n",
        "      #In order to roll_again next round, three things must all happend: \n",
        "      #1. You are not busted\n",
        "      #2. You chose to roll again last time \n",
        "      #3. You chose to roll again this time \n",
        "      roll_again_state = jnp.logical_and( jnp.logical_and( not_busted_state,roll_again_state), new_roll_again_state) \n",
        "      \n",
        "      \n",
        "      if Verbose : print(\"----Roll Iteration: \", roll_num,\"\\n\", \"Busted_State: \",jnp.logical_not(not_busted_state),\"Roll_Again_State: \",roll_again_state)\n",
        "    \n",
        "    #-----------------------\n",
        "    #End of the players turn:\n",
        "    #-----------------------\n",
        "    \n",
        "    #This line resets the runners of anyone who had busted to zero\n",
        "    runner_col_state = runner_col_state * not_busted_state\n",
        "\n",
        "    #Update the player positions!\n",
        "    player_col_state = update_player_col_state(active_player_index,player_col_state,runner_col_state)\n",
        "    \n",
        "    if Verbose:\n",
        "      [print(f\"player_col_state Sim #{i} \\n\",player_col_state[:,:,i]) for i in range(N_PARR)]\n",
        "\n",
        "    player_N_col_claimed = calculate_player_N_col_claimed(player_col_state)\n",
        "\n",
        "    \n",
        "    game_in_progress = jnp.logical_and( game_in_progress, jnp.all(player_N_col_claimed < N_COL_TO_WIN, axis=0))\n",
        "    if Verbose: print(f\"Turn # {turn_num}. Games in progress: {jnp.sum(game_in_progress)}\")\n",
        "   \n",
        "  #At the end of this loop, one player has won!\n",
        "  if Verbose : \n",
        "    print(\"GAME OVER!\") \n",
        "    print(f\"Number of rolls simulated {roll_num}\")\n",
        "    print(f\"Final number of columns claimed \\n {player_N_col_claimed}\")\n",
        " \n",
        "  return jnp.sum( player_N_col_claimed >= N_COL_TO_WIN , axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6lLhiX1y01q"
      },
      "outputs": [],
      "source": [
        "def monte_carlo_test_state(AI, n_games, init_state=None, Verbose=False):\n",
        "  outcome = simulate_game_parr(AI, N_PARR=n_games, PLAYER_COL_STATE_INIT=init_state, Verbose=Verbose)\n",
        "  prob_to_win = outcome[0]/n_games\n",
        "  return prob_to_win\n",
        "\n",
        "def monte_carlo_and_v_func(w, enemy_AI, n_games, init_state):\n",
        "  mc_value = monte_carlo_test_state([Good_AI_vmap, enemy_AI], n_games, init_state)\n",
        "  value = Good_v_func(w, 0, init_state, calculate_player_N_col_claimed(init_state), calculate_illegal_col(init_state), jnp.zeros(11))\n",
        "  print(f\"MC = {mc_value}, v_func = {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLTmxtqV9KsL"
      },
      "outputs": [],
      "source": [
        "def compare_MC_to_v_func_test(w, enemy_AI, n_games):\n",
        "  '''This function will test a bunch of initial states by printing the monte carlo probability of winning\n",
        "      and then printing the v_func estimate of winning, these should be similar'''\n",
        "\n",
        "  # !! THIS FUNCTION CAN TAKE A LONG TIME TO RUN !!\n",
        "  init_state = jnp.array([[1,1,1,1,1,1,1,1,1,1,1], [1,1,1,1,1,1,1,1,1,1,1]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [0,0,3,9,11,13,11,9,7,0,0]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,3,11,4,11,1,3,5,3], [0,5,3,9,11,1,11,9,7,2,0]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [0,5,7,9,0,0,0,9,7,5,0]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [3,5,7,9,11,13,11,9,7,5,3]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,0,9,11,13,11,9,7,5,3], [3,5,0,9,11,13,11,9,7,5,3]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [3,5,7,9,11,0,11,9,7,5,3]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [3,5,7,9,11,0,0,9,7,5,3]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [3,5,7,9,11,0,0,0,7,5,3]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [3,5,7,9,11,0,0,0,0,5,3]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [3,5,7,9,11,0,0,0,0,0,3]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,11,13,11,9,7,5,3], [0,5,7,9,11,13,11,9,7,5,0]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[0,5,7,9,11,0,11,9,7,5,0], [0,0,7,9,11,13,11,9,7,5,0]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)\n",
        "\n",
        "  init_state = jnp.array([[3,5,7,9,0,13,0,9,7,5,3], [0,5,7,9,11,13,11,9,7,5,0]])\n",
        "  monte_carlo_and_v_func(w, enemy_AI, n_games, init_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5o13sfrCpAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d545f7-5507-4663-ec54-6af84417d897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.97800004\n"
          ]
        }
      ],
      "source": [
        "mc_value = monte_carlo_test_state([Good_AI_vmap, random_timid_AI_vmap], 500)\n",
        "print(mc_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKMdSUVt-vZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54642313-78a5-434c-c7b2-0da0fa42c194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MC = 0.718000054359436, v_func = 0.6771398782730103\n",
            "MC = 0.0010000000474974513, v_func = 0.019828803837299347\n",
            "MC = 0.16600000858306885, v_func = 0.15622536838054657\n",
            "MC = 0.0, v_func = 0.016315674409270287\n",
            "MC = 0.562000036239624, v_func = 0.5585915446281433\n",
            "MC = 0.5750000476837158, v_func = 0.5579010248184204\n",
            "MC = 0.3530000150203705, v_func = 0.37356802821159363\n",
            "MC = 0.2370000183582306, v_func = 0.20314764976501465\n",
            "MC = 0.10000000149011612, v_func = 0.10526865720748901\n",
            "MC = 0.032999999821186066, v_func = 0.045493628829717636\n",
            "MC = 0.0, v_func = 0.019176321104168892\n",
            "MC = 0.19200000166893005, v_func = 0.16148796677589417\n",
            "MC = 0.6060000061988831, v_func = 0.5154905319213867\n",
            "MC = 0.5470000505447388, v_func = 0.5316169857978821\n"
          ]
        }
      ],
      "source": [
        "w = jnp.array([ 0.1035391 ,  0.02324084,  0.00629771, -0.01452476,  0.00655654,  0.00639482,  0.28484833,  0.20598306,\n",
        "  0.12112736,  0.05217794  ,0.11130193  ,0.08123927  ,0.27438858  ,0.2049303   ,0.11780114  ,0.03907273,\n",
        "  0.10480063,  0.07496218  ,0.20313375  ,0.2138879   ,0.20972085  ,0.24800974  ,0.19582418  ,0.12072659,\n",
        "  0.2825165 ,  0.23228781  ,0.24480774  ,0.11446477  ,0.1909898   ,0.09358135  ,0.69109344  ,0.6588065,\n",
        "  0.23544775])\n",
        "compare_MC_to_v_func_test(w, Good_AI_vmap, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co2SOhJ4CNQ7"
      },
      "source": [
        "# Final AI! \n",
        "\n",
        "\n",
        "This AI was trained for 10000 games against itself and has achieved:\n",
        "\n",
        "- ~99% win rate **vs** pure random AI\n",
        "- ~95% win rate **vs** random timid AI\n",
        "- ~75% win rate **vs** runner weights AI\n",
        "\n",
        "Description of Features:\n",
        "\n",
        "|Feature (# weights)    | Description  |\n",
        "|-----|-----|\n",
        "|Runner Location (6)|The distance the runners have advanced in each column this turn|\n",
        "|Player Column (6)|The distance the player is from claiming each column|\n",
        "|Enemy Column (6)|The distance the enemy is from claiming each column|\n",
        "|Player Col Claimed (6)|The columns the player has claimed|\n",
        "|Enemy Col Claimed (6)|The columns the enemy has claimed|\n",
        "|Player N Col Claimed (1)|The number of columns the player has claimed|\n",
        "|Enemy N Col Claimed (1)| The number of columns the enemy has claimed|\n",
        "|Affine (1)| Allows for affine functions (non-zero intercept)|\n",
        "\n",
        "### Improvement through training (by % wins of 1000 games against runner weights AI)\n",
        "\n",
        "| # Games Trained | Win % (of 1000 games) |\n",
        "|--|--|\n",
        "| 0 | 00.0 |\n",
        "| 100 | 17.4 |\n",
        "| 1000 | 43.0 |\n",
        "| 2000 | 59.2 |\n",
        "| 3000 | 62.2 |\n",
        "| 5000 | 65.6 |\n",
        "| 10000 (against itself) | 75.0 |\n",
        "\n",
        "### Areas to Improve\n",
        "\n",
        "- When an opponent is close to claiming a column, the AI knows to stay away from the column.\n",
        "  - However, it also avoids the corresponding column on the opposite side of the board (by symmetry).\n",
        "    - I would like to introduce a new feature that uses the **runner location**, **player column**, and **enemy column**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ru9FTKdCPQu"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def Good_AI(active_player_index, player_col_state, choices, legal, random_key):\n",
        "  '''An AI function using some weights w which are assumed to be a global variable'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - whose turn it is\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # choices - an array of possible choices that the AI can make\n",
        "  # legal - an array of which choices are legal\n",
        "  #Output:\n",
        "  # best_choice_index - if there is a legal choice, this is the legal choice that gives the highest estimated probability to win;\n",
        "  #                     if there is no legal choice it gives the illegal choice with the highest estimated probability to win.\n",
        "  # roll_again - choice whether to roll again or stay - this is whatever choice gives the highest estimated probability to win.\n",
        "\n",
        "  # hardcoded weights\n",
        "  w = jnp.array([0.1035391, 0.02324084, 0.00629771, -0.01452476, 0.00655654, 0.00639482, 0.28484833, 0.20598306, 0.12112736, 0.05217794, 0.11130193, 0.08123927, 0.27438858, 0.2049303, 0.11780114, 0.03907273, 0.10480063, 0.07496218, 0.20313375, 0.2138879, 0.20972085, 0.24800974, 0.19582418, 0.12072659, 0.2825165, 0.23228781, 0.24480774, 0.11446477, 0.1909898, 0.09358135, 0.69109344, 0.6588065, 0.23544775])\n",
        "\n",
        "  #Calculate N columns claimed and the illegal columns to be used in the AI\n",
        "  player_N_col_claimed = calculate_player_N_col_claimed(player_col_state)\n",
        "  illegal_col = calculate_illegal_col(player_col_state)\n",
        "\n",
        "  #This passes all the choices into the value function at once\n",
        "  # The result is a vector of shape (9,) with the value of each of the 9 options\n",
        "  all_vals = Good_v_func(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, choices)\n",
        "  \n",
        "  #Take the maximum but only overthose that are legal!\n",
        "  # (multuplying by \"legal\" sets the value of any illegal moves to 0)\n",
        "  best_choice_index = jnp.argmax(all_vals*legal)\n",
        "\n",
        "  #Deciding whether or not to roll again (uses the Q function)\n",
        "  #Compute the value for rolling again and staying from that state.\n",
        "  runner_col_state = choices[best_choice_index]\n",
        "\n",
        "  # the value if we roll a\n",
        "  q_roll_again_val = Good_q_roll_again(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state)\n",
        "  q_stay_val = Good_q_stay(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state)\n",
        "\n",
        "  # checks if the value of rolling again is higher than the value of staying\n",
        "  # in this case we should roll again\n",
        "  roll_again = q_roll_again_val > q_stay_val\n",
        "\n",
        "  N_runners = jnp.count_nonzero(choices[best_choice_index])\n",
        "    \n",
        "  return best_choice_index, roll_again\n",
        "\n",
        "def reflect_column_weights(w):\n",
        "  '''Takes in 6 weights and reflects them around the middle column to cover all 11 columns'''\n",
        "  #Input: \n",
        "  # w - array of shape (6,) of the weights to reflect\n",
        "  #Output:\n",
        "  # array of shape (11,) of the reflected weights around the middle column\n",
        "  \n",
        "  reflected_w = jnp.zeros(11)\n",
        "  reflected_w = reflected_w.at[0:6].set(w[0:6])\n",
        "  reflected_w = reflected_w.at[6:12].set(w[4::-1])\n",
        "  return reflected_w\n",
        "\n",
        "@jit\n",
        "def Good_v_func(w,active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state):\n",
        "  '''Value function for the AI. Estimates the probability of the active player to win. (i.e. the value of the game where +1 for a win and 0 for a loss)'''\n",
        "  # divide the weights w into three categories\n",
        "  runner_w = w[0:6] # weights for runner location features\n",
        "  player_col_w = w[6:12] # the amount we have advanced in each column\n",
        "  enemy_col_w = w[12:18] # the amount the enemy has advanced in each column\n",
        "  player_col_claim_w = w[18:24] # weights for the columns that we have claimed\n",
        "  enemy_col_claim_w = w[24:30] # weights for the columns that the enemy has claimed\n",
        "  player_N_col_claimed_w = w[30] # weights for number of columns we have claimed\n",
        "  enemy_N_col_claimed_w = w[31] # weights for the number of columns the enemy has claimed\n",
        "  affine_w = w[32] # this weight just allows for affine functions\n",
        "\n",
        "  # we use symmetry to reduce number of weights, so here we reflect the weights\n",
        "  # so they cover all 11 columns.\n",
        "  runner_w = reflect_column_weights(runner_w)\n",
        "  player_col_w = reflect_column_weights(player_col_w)\n",
        "  enemy_col_w = reflect_column_weights(enemy_col_w)\n",
        "  player_col_claim_w = reflect_column_weights(player_col_claim_w)\n",
        "  enemy_col_claim_w = reflect_column_weights(enemy_col_claim_w)\n",
        "\n",
        "  score = jnp.inner(runner_w, runner_col_state)\n",
        "\n",
        "  # we look only at the difference in player locations here\n",
        "  column_lengths = jnp.array([3, 5, 7, 9, 11, 13, 11, 9, 7, 5, 3])\n",
        "  player_col = (column_lengths - player_col_state[active_player_index])*(1 - illegal_col)\n",
        "  enemy_col = (column_lengths - player_col_state[1 - active_player_index])*(1 - illegal_col)\n",
        "\n",
        "  score += jnp.inner(player_col_w, player_col)\n",
        "  score -= jnp.inner(enemy_col_w, enemy_col)\n",
        "  \n",
        "  # here we look only at the difference in the N col climaed between the two players\n",
        "  player_col_claimed = jnp.where(player_col_state[active_player_index] < 1, 1, 0)\n",
        "  enemy_col_claimed = jnp.where(player_col_state[1 - active_player_index] < 1, 1, 0)\n",
        "\n",
        "  # calculates the precentage of the column we have claimed\n",
        "\n",
        "  score += player_N_col_claimed[active_player_index] * player_N_col_claimed_w\n",
        "  score -= player_N_col_claimed[1 - active_player_index] * enemy_N_col_claimed_w\n",
        "\n",
        "  score += jnp.inner(player_col_claim_w, player_col_claimed)\n",
        "  score -= jnp.inner(enemy_col_claim_w, enemy_col_claimed)\n",
        "\n",
        "  score += affine_w\n",
        "\n",
        "  #Apply a sigmoid to the score so that the value function is always between 0 and 1\n",
        "  return jnn.sigmoid(score)\n",
        "\n",
        "@jit\n",
        "def Good_q_roll_again(w,active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state):\n",
        "  '''Find the approximated value for rolling again in terms of the value function v'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - whose turn it is\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # player_N_col_claimed - the number of columns each player has claimed\n",
        "  # illegal_col - the current columns that cannot be played in\n",
        "  # runner_col_state - the distance runner has travelled in each column\n",
        "  #Output:\n",
        "  # An estimate of the probability to win given that we choose to stay.\n",
        "  \n",
        "  #Compute the score if we would bust\n",
        "  zero_runner = jnp.zeros(11, dtype=jnp.dtype('u1')) \n",
        "  bust_value = 1 - Good_v_func(w, 1 - active_player_index, player_col_state, player_N_col_claimed, illegal_col, zero_runner) \n",
        "\n",
        "  # calculates the probabilities of advancing 1 or 2 in each column\n",
        "  # adv_probs = calc_adv_probs()\n",
        "  # i hard code this!\n",
        "  adv_probs = jnp.array([[0.02700617, 0.05246913, 0.07638889, 0.09876543, 0.11959876, 0.13888888, 0.11959876, 0.09876543, 0.07638889, 0.05246913, 0.02700617], [0.0007716, 0.00308642, 0.00694444, 0.01234568, 0.01929012, 0.02777778, 0.01929012, 0.01234568, 0.00694444, 0.00308642, 0.0007716]])\n",
        "\n",
        "  #Compute the score if we would not bust\n",
        "  N_runner = jnp.count_nonzero(runner_col_state)\n",
        "\n",
        "  # calculates the expected amount of spaces we advance by\n",
        "  advance_runner = runner_col_state + (1 * adv_probs[0] + 2 * adv_probs[1]) * ((runner_col_state > 0) + (1 - illegal_col) * (3 - N_runner))\n",
        "  advance_value = Good_v_func(w, active_player_index, player_col_state, player_N_col_claimed, illegal_col, advance_runner)\n",
        "\n",
        "  # find the probability of busting\n",
        "  p_bust = cant_stop_bust_probability(runner_col_state,illegal_col)\n",
        "\n",
        "  # the answer is the convex combination of the bust value and advance value using p_bust\n",
        "  return p_bust * bust_value + (1 - p_bust) * advance_value\n",
        "\n",
        "@jit\n",
        "def Good_q_stay(w,active_player_index, player_col_state, player_N_col_claimed, illegal_col, runner_col_state):\n",
        "  '''Returns the value (according to the value function v) of staying'''\n",
        "  #Input:\n",
        "  # w - the weights\n",
        "  # active_player_index - whose turn it is\n",
        "  # player_col_state - distance each player is away from claiming each column\n",
        "  # player_N_col_claimed - the number of columns each player has claimed\n",
        "  # illegal_col - the current columns that cannot be played in\n",
        "  # runner_col_state - the distance runner has travelled in each column\n",
        "  #Output:\n",
        "  # An estimate of the probability to win given that we choose to stay.\n",
        "\n",
        "  # if we stay, the runners advance and we can update our game state\n",
        "  updated_player_col_state = update_player_col_state(active_player_index,player_col_state,runner_col_state) \n",
        "  updated_player_N_col_claimed = calculate_player_N_col_claimed(updated_player_col_state)\n",
        "  updated_illegal_col = calculate_illegal_col(updated_player_col_state)\n",
        "\n",
        "  # the runners will return to zero\n",
        "  zero_runner = jnp.zeros(11, dtype=jnp.dtype('u1')) \n",
        "\n",
        "  # since v_func is estimating the probability of the active player to win,\n",
        "  # if we choose to stay we need to do P(we win) = 1-P(other player wins)\n",
        "  return 1 - Good_v_func(w, 1 - active_player_index, updated_player_col_state, updated_player_N_col_claimed, updated_illegal_col, zero_runner)\n",
        "\n",
        "# vmap\n",
        "Good_AI_vmap = jax.vmap(Good_AI, in_axes=(None, 2, 2, 1, 0), out_axes=0 )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights over time\n",
        "Weights:\n",
        "\n",
        "After 100 Games: \n",
        "\n",
        "[0.07617867, 0.03101422, 0.02089879, 0.01368502, 0.0078908,  0.00360821, 0.10811867, 0.09612512, 0.09594401,\n",
        " 0.11058875, 0.09506108, 0.05413193, 0.09675168, 0.10194193 ,0.09625064, 0.10252529, 0.09696958 ,0.04687759,\n",
        " 0.10842792, 0.11154703, 0.11574828, 0.11095291, 0.10790873 ,0.10080186, 0.10217196, 0.09962047 ,0.1082868,\n",
        " 0.10183044, 0.10172137, 0.09769899, 0.1553869 , 0.11133002 ,0.12203544]\n",
        "\n",
        "After 1000 Games:\n",
        "\n",
        "[0.0409123 , 0.00835584, 0.00770477, 0.00658723, 0.00382924, 0.00194145, 0.10266912, 0.08842536 ,0.08659112,\n",
        " 0.06801992, 0.0505174 , 0.04613237, 0.09144995, 0.09072597, 0.0901193 , 0.0740177 , 0.05003512 ,0.04198749,\n",
        " 0.10769407, 0.1147806 , 0.13379127, 0.12638041, 0.11165017, 0.10124733, 0.10638765, 0.1089701  ,0.12664862,\n",
        " 0.11273444, 0.10065236, 0.09947819, 0.1955417 , 0.15487361, 0.13705587]\n",
        "\n",
        "After 2000 Games:\n",
        "\n",
        " [0.03452276, 0.0067145,  0.00645219, 0.00588437, 0.00472891, 0.00477389, 0.10040201, 0.08637246, 0.07309923,\n",
        " 0.06045679 ,0.04568635, 0.02996191 ,0.09392036 ,0.09121624 ,0.07328227 ,0.06145701 ,0.04417024 ,0.03131298,\n",
        " 0.10900202 ,0.12652776, 0.13936937 ,0.12773804 ,0.1169558  ,0.10040541 ,0.11235666 ,0.122553   ,0.13532351,\n",
        " 0.11369655 ,0.10309941, 0.09740062 ,0.21999891 ,0.18443018 ,0.13609365]\n",
        "\n",
        " After 3000 Games:\n",
        "\n",
        " [0.03016623 ,0.0074396,  0.00928442, 0.00579329, 0.00699066, 0.00678289, 0.10306276, 0.07727478, 0.07287303,\n",
        " 0.05113595 ,0.03762379, 0.02894804, 0.09859531 ,0.08377281 ,0.07241321 ,0.05437551 ,0.03759806 ,0.03042124,\n",
        " 0.11911649 ,0.1203796 , 0.14076614, 0.13266423 ,0.12066723 ,0.10322393 ,0.12343781 ,0.11599024 ,0.13647184,\n",
        " 0.1169002  ,0.10455729, 0.09850085, 0.2368132  ,0.19585846 ,0.13411663]\n",
        "\n",
        " After 5000 Games:\n",
        "\n",
        " [ 0.03540692 , 0.0107718 ,  0.00804657 ,-0.00699463 , 0.00481385 , 0.00375036 , 0.10548824 , 0.07742934,\n",
        "  0.06493578  ,0.01399624 , 0.0463188  , 0.03736152 , 0.1020679  , 0.08202828 , 0.06522607 , 0.01529308,\n",
        "  0.04672097 , 0.03780698 , 0.13181761 , 0.13382572 , 0.13381454 , 0.13444152 , 0.11956096 , 0.10478327,\n",
        "  0.14010414 , 0.13326086 , 0.13248673 , 0.11152916 , 0.10718318 , 0.098153   , 0.25824648 , 0.22271901,\n",
        "  0.12247454]\n",
        "\n",
        "After retraining against itself 10 times (1000 games each):\n",
        "\n",
        " [ 0.1035391 ,  0.02324084,  0.00629771, -0.01452476,  0.00655654,  0.00639482,  0.28484833,  0.20598306,\n",
        "  0.12112736,  0.05217794  ,0.11130193  ,0.08123927  ,0.27438858  ,0.2049303   ,0.11780114  ,0.03907273,\n",
        "  0.10480063,  0.07496218  ,0.20313375  ,0.2138879   ,0.20972085  ,0.24800974  ,0.19582418  ,0.12072659,\n",
        "  0.2825165 ,  0.23228781  ,0.24480774  ,0.11446477  ,0.1909898   ,0.09358135  ,0.69109344  ,0.6588065,\n",
        "  0.23544775]"
      ],
      "metadata": {
        "id": "TAtWeaR2UlBI"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BP4PMjNiK9oz",
        "pCJT-pJc532s",
        "o-Xrhe6fEGQG",
        "0SkJvX0yLIup",
        "H3TDpEmwAUV1",
        "buH2WaFlcBmB"
      ],
      "name": "FinalProject.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}